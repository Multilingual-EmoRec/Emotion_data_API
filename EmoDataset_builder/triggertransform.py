from itertools import chain
import urllib.request as urllib2
import requests
import codecs
import warnings

import pandas as pd
import numpy as np
from nltk import tokenize
import nltk

nltk.download('punkt')

def api_call(word, label, corpus, limit, sentence_len):
    word_url = url_encode(word)
    url = "https://www.dwds.de/r/?q=" + word_url + "&limit=" + str(limit) + "&corpus="+ corpus + "&view=tsv"
    df = pd.read_csv(url, sep='\t', encoding="utf-8")

    if df.Hit.isnull()[0] == True:
        raise Exception("word does not exist in corpus")
        
    df = df[df['Hit'].str.split().str.len().lt(sentence_len)]
    df = df[~df['Hit'].str.split().str.len().lt(2)]
    df = df.Hit.map(tokenize.sent_tokenize)
    df = list(chain.from_iterable(df))
    df = [s for s in df if any(xs in s for xs in [word])]

    df = pd.DataFrame({'label': len(df) * [label],
                       'text_de': df})
    
    df['corpus'] = corpus
    df['keyword'] = word
    
    return df 


def del_negation(df):
    df = df.dropna()
    df.reset_index(drop=True, inplace=True)
    df['text_de'] = df['text_de'].str.lower()
    
    df = df[~df['text_de'].str.contains('nicht')]
    df = df[~df['text_de'].str.contains('ohne')]
    df = df[~df['text_de'].str.contains('keine')]
    df = df[~df['text_de'].str.contains('kein')]
    df = df[~df['text_de'].str.contains('keinen')]
    df = df[~df['text_de'].str.contains('keinem')]
    df = df[~df['text_de'].str.contains('keiner')]
    df = df[~df['text_de'].str.contains('\?')]

    return df

def url_encode(word):
    word = codecs.encode(word, 'utf-8')
    url_Word = urllib2.quote(word)

    return url_Word

def generate_example_text_based_on_keywords(word: str, label: str, limit=200, sentence_len=12):
    """
    A function used to generate sentences based on one (or more) words.
    ...
    Attributes
    ----------
    word : str
        give a word(s) to get  the sentence the word(s) appears in
    corpus : str
        the used corpus of the API. (default=korpus21)
    label : str
        give a label to the word, which will be provided through output
    limit : int
        number of sentences being generated by the API (default=80)
    sentence_len : str
        length of sentence of a generated sentence by the API (default=12)
    """
    warnings.warn("Connection to the internet needs to be kept. No Error handling")
    
    corpus_list = ['korpus21', 'blogs', 'zeit', 'untertitel']

    df = [api_call(word, label, corpus, limit, sentence_len) for corpus in corpus_list]
    df = pd.DataFrame(df)
    df = pd.concat([i for i in df[0]], ignore_index=True, sort=False)
        
    if df.empty:
        df = df.append([np.nan], ignore_index=True)
        return df

    df = del_negation(df)
    
    df.drop_duplicates(subset=['text_de'], inplace=True)
    df.reset_index(drop=True, inplace=True)
    
    return df

if __name__ == "__main__":
    #example print
    print(generate_example_text_based_on_keywords("schnell", "neutral"))
    